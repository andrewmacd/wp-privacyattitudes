---
title: "(No) Privacy Please!: What Determines Chinese Attitudes Toward Online Government Monitoring"
date: '`r format(Sys.time(), "%B %d, %Y")`'
format: 
  pdf:
    fig-pos: 'h'
    tbl-pos: 'h'
author:
  name: Andrew W. MacDonald
  orcid: 0000-0002-4695-1560
  email: andrew.macdonald@dukekunshan.edu.cn
  affiliation: 
    name: Duke Kunshan University
    city: Kunshan
    url: https://www.andrewmacdonald.org/
abstract: > 
  This study investigates the determinants of public opinion toward government monitoring in China. The existing literature on the acceptance of government monitoring raises several open questions, including the extent to which demographic variables influence the relationship, how government trust relates to the acceptance of government monitoring, and whether the acceptance of public versus private monitoring shares the same determinants. Using a two-wave survey conducted before and after the Covid-19 lockdowns in China, the study finds that: 1) demographic factors do not seem to be related to the acceptance of government monitoring; 2) government trust does predict attitudes, although the Covid-19 experience has significantly modified this relationship; and 3) the acceptance of private monitoring appears to have different determinants. The study concludes by considering some implications of these findings.
keywords: 
  - Digital Privacy
  - Covid-19
  - Authoriatrian Regimes
  - Government Trust
  - China
execute: 
  echo: false
  warning: false
keep-tex: true
number-sections: true
bibliography: references.bib
csl: telematics.csl
---

```{r}
#| label: setup
#| include: FALSE

library(tidyverse)
library(kableExtra)
library(modelsummary)
library(estimatr)
library(psy)
library(broom)
library(sjPlot)
library(sjmisc)
library(dagitty)
library(ggdag)
library(lavaan)
library(scales)

load(file="../../privacy.attitudes.RData")

set.seed(88888888)

cronbach.total.track <- privacy %>% 
  select(gm1, gm2, track4, track5) %>% 
  mutate(track4 = as.numeric(track4),
         track5 = as.numeric(track5),
         gm1 = as.numeric(gm1),
         gm2 = as.numeric(gm2))

ca.tt <- cronbach(cronbach.total.track)

cronbach.ts <- privacy %>% 
  select(ts1, ts2, ts3) %>% 
  mutate(ts1 = as.numeric(ts1),
         ts2 = as.numeric(ts2),
         ts3 = as.numeric(ts3))

ca.ts <- cronbach(cronbach.ts)

cronbach.k <- privacy %>% 
  select(k1, k4, k5, k6) %>% 
  mutate(k1 = as.numeric(k1),
         k4 = as.numeric(k4),
         k5 = as.numeric(k5),
         k6 = as.numeric(k6))

ca.k <- cronbach(cronbach.k)

cronbach.gp <- privacy %>% 
  select(gp1, gp2) %>% 
  mutate(gp1 = as.numeric(gp1),
         gp2 = as.numeric(gp2))

ca.gp <- cronbach(cronbach.gp)
```

## Introduction {#sec-introduction}

The dramatic events of the Covid-19 era have brought to the forefront citizens' relationships with government tracking technologies. Users were often required to install government apps that monitored their location, the stores they entered, and even whether they purchased cold medicines [@mcmorrow2022]. Nowhere was this tracking more invasive than in China, where the government mobilized technological tools to deeply peer into the daily lives of its citizens. The impact of these events on users' attitudes toward technological monitoring has not yet been fully described. Utilizing a unique dataset, this study resolves several open questions in the literature regarding how citizens view government monitoring.

Citizens' attitudes toward government intrusions into their online privacy is an understudied area, with numerous unanswered questions in the literature [@gómez-barroso2018], particularly regarding how citizens view this topic in authoritarian and non-Western contexts. One unresolved question is the extent to which demographic or privacy knowledge variables predict attitudes. Literature on general privacy offers several suggestions as to which variables may shape attitudes, but little research has been undertaken to determine if these findings apply to attitudes toward government monitoring. To the extent that there is consensus in the literature, it agrees that government trust should be strongly related to attitudes toward government tracking. However, this literature has not reached a consensus on how an event like the Covid-19 lockdowns might alter this relationship, nor has it provided direct causal tests of the relationship. Furthermore, it is not clear whether the variables that predict attitudes toward government tracking should also predict attitudes toward private tracking.

To address these gaps in the literature, this study utilizes two waves of a survey conducted before and after the 2022 Covid-19 lockdowns in China to develop models of respondents' attitudes. The first model examines a set of demographic and technology knowledge variables as predictors for acceptance of government tracking and finds that the models are poor fits, with few variables achieving statistical or substantive significance. The second set of models adds government trust as a predictor variable and finds, as expected, that government trust is an important predictor of attitudes. A mediation model is then developed that separates the direct effect of Covid-19 on attitudes toward government tracking from the indirect effect of Covid-19 on government trust, which subsequently influences attitudes toward government monitoring. This mediation model finds that the overall effect of Covid-19 is positive but complex, with the direct and indirect effects operating in opposing directions. Finally, the paper examines a model to test whether any of the predictor variables for public tracking can predict attitudes toward private tracking; the model's results suggest that they cannot.

Taken together, these results indicate that government trust matters but what may be equally important is the public perception of the rationale for government tracking. The conclusion discusses these results in the context of the existing literature and highlights some important implications and areas for future research.

## Literature review {#sec-litreview}

### Background

What predicts respondents' attitudes toward government tracking of their online activity has generated significant scholarly interest in the last ten years, yet the findings have not reached any firm conclusions on a number of important questions [@reddick2015]. Compounding this issue, to date, most research on the topic has been conducted primarily with U.S. or Western respondents, with comparatively fewer studies reporting on developing or non-democratic countries. This research agenda has gained new urgency during the Covid-19 pandemic, as governments around the world have engaged in highly intrusive monitoring and data collection activities.

From the pre-Covid privacy literature, two important findings are prominent. The first is that demographic variables are significant predictors of attitudes toward generalized online privacy. In a notable early study of early Internet users, Sheehan found that education and age are two significant determinants of online privacy attitudes [@sheehan2002]. Others have replicated this result and found that characteristics such as gender, social setting, and income also play a role in forming privacy expectations [@anwar2017; @büchi2021; @lee2019]. The second finding is that respondents' personal experience with privacy and technology is also an important factor in predicting privacy attitudes. Baskaran and Mathew report that users with significant knowledge of and interest in privacy have a greater fear of losing their privacy, and this fear motivates them to change their online behavior [@baskaran2024]. Dupree et al. suggest that various possible online user typologies exist, with user experience being a significant variable that matters that can potentially shift respondents to an extreme view in either direction [@dupree2016]. Kokolakis, as part of a meta-analysis of privacy, notes that young people may be more aware of their online privacy context and therefore more active in policing their privacy boundaries [@kokolakis2017], a finding that Blank et al. have replicated [@blank]. These findings suggest that personal characteristics and background are important determinants of privacy attitudes, though how these findings relate to government monitoring specifically remains unclear.

The second key finding is that trust in the state is a significant correlate of whether respondents feel anxious about government monitoring of their online behavior. Davis and Silver discovered that Americans with lower levels of trust in the government were less willing to accept government surveillance programs after the 9/11 terrorist attacks [@davis2004]. Pavone and Esposti determined that users either trusted the government and therefore did not find proposed monitoring concerning, or they did not trust the government and thus perceived any monitoring as threatening [@pavone2012]. Trüdinger and Steckermeier found that acceptance of government surveillance in Germany depends on how much respondents trust the state [@trüdinger2017]. However, this literature has so far been unable to causally link trust and acceptance of monitoring. It is possible that acceptance of government monitoring is downstream of government trust, but it could also be that government trust and monitoring are both influenced by personality or demographic attributes. It is also unclear from these studies how rapidly or under what types of events might change government trust and then whether that change in trust would subsequently alter attitudes toward acceptance of government tracking.

The literature on government monitoring of citizens increased dramatically following the onset of the Covid-19 pandemic, though most findings echo those of Pavone and Esposti and other earlier scholars. Because the Covid-19 pandemic introduced a wide array of new tracking technologies, scholars have focused directly on users' and respondents' feelings regarding government monitoring (for a sampling of the extensive literature, see [@abramova2022; @garrett2021; @ioannou2021; @ong; @wnuk2020]). To highlight one example of Covid-era research, Ioannou and Tussyadiah linked state trust, surveillance acceptance, and perceived necessity in explaining the variation in willingness to use contact tracing apps in the U.S. Generally, this research finds that Covid-19 is an important factor in shaping views on tracking. However, most of this research tests acceptance of specific monitoring technologies (such as vaccine passports) or examines attitudes only in close temporal proximity to the technology's usage and therefore offers limited information about the durability of these attitudes.

Additionally, how these findings translate to the Chinese context is not obvious. While recent research has begun to develop a picture of Chinese attitudes towards government monitoring, some important questions remain unanswered. Several studies have found that Chinese respondents are generally more willing to use or accept government surveillance technologies across various technology types [@habich-sobiegalla2023; @kostka2021; @kostka2024]. Liu and Kostka, in separate studies, both establish that trust in the state correlates with increased acceptance of the social credit system (Liu) and surveillance broadly (Kostka) [@kostka2023; @liu2022]. However, to date, there have been no major studies that have conducted a before-and-after analysis of attitude change as a result of China's Covid-19 experiences.

Finally, a line of research investigates whether differences in attitudes exist if the surveillance is conducted by the government versus a private entity. Steinfeld finds differences in attitudes between the two, with the justification for surveillance being a key factor for government monitoring acceptance (accepting the War on Terror as essential) and compensatory benefits being the strongest predictor of private monitoring acceptance [@steinfeld2017]. Nam indicates that it is primarily demographic features that predict generalized privacy concerns, while government privacy concerns are chiefly predicted by trust in the government [@nam2019]. These studies both focus on Americans and therefore it is unclear how generalizable their results are. Research in China by Steinhardt et al. finds that users in China tend to trust the government with their data more than they do private corporations, but does not explore the specific determinants of this variation in trust [@steinhardt2022].

### Contribution

This work aims to make three contributions to the literature on government surveillance. First, it seeks to clarify which demographic and attitudinal factors are significant in predicting privacy concerns. Previous findings have supported the idea that certain respondent attributes predict acceptance of government surveillance; if these findings do not find support here, it may suggest that demographics are a poor fit in explaining respondent attitudes towards government tracking not just in China.

Second, this study aims to establish to what degree and in what ways government trust and government privacy attitudes are linked. So far, there have been very few studies of privacy attitudes that are not purely cross-sectional. The survey used in this paper was conducted in two waves, one before the strict Covid-19 controls were implemented in China, and another wave just after the controls were relaxed, which helps add additional leverage to explore how events and context may also matter for shifting attitudes. In particular, during this period, as You et al. have found, the Chinese response to the pandemic engendered significant criticism and resulted in a decline in trust in the government [@you2024]. This study can help determine if government trust is an important predictor of attitudes, and, if it is, whether a decline in trust along with event-specific effects mechanically lead to a lower level of acceptance of government monitoring.

Finally, the study aims to determine whether the factors influencing acceptance of tracking differ depending on whether the tracking is conducted by private entities or government organizations. If different determinants exist, it would imply that users are cognizant of the political context of government monitoring and that this awareness shapes their attitudes. This distinction is important given that much of the existing research on the formation of privacy attitudes focuses on private monitoring [@gómez-barroso2018].

### Hypotheses

The existing literature and the specific features of this survey generates a set of testable hypotheses, $H_1$ through $H_6$.

$H_1$: Demographic variables such as age, education, and income predict acceptance of government monitoring

A finding here that certain demographic factors are predictors of attitudes toward government monitoring can help clarify whether the demographic linkages found in research on generalized privacy attitudes or attitudes toward private monitoring are similar for attitudes toward government monitoring.

$H_{2a}$ Technical know-how and privacy consciousness predicts acceptance of government monitoring

$H_{2b}$: Technical know-how and privacy consciousness does not predict acceptance of government monitoring

Existing literature finds that those with significant experience or knowledge of information and communication technologies (ICTs) are more careful with their online privacy. However, it is also the case that the Chinese online information environment is highly controlled, particularly with respect to any information critical of the government [@han2018] so such knowledge may have less of an impact on attitudes. Government propaganda extolling the benevolence of the state with regards to protecting users [@gainous2023] may even counteract or reverse the fear effect of greater knowledge of privacy. Therefore, privacy knowledge and technical skill may also be uncorrelated or even positively correlated with support for government monitoring.

$H_3$: Trust in government should predict acceptance of government monitoring

Both existing studies of Chinese users and those outside of China have all found this relationship to be a relatively robust one. Research on China has also found that government trust is an important predictor of many other social and attitudinal variables [@chen2017; @qiu2012; @zhou2018].

$H_4$: The pandemic should alter the acceptance of government monitoring

This hypothesis could be true in two different ways. The first way is via a direct effect - the experience of intrusive and long-lasting surveillance could lower support for government monitoring. Alternately, it could increase support for government monitoring if the population viewed the surveillance as socially beneficial. The second way is via an indirect effect - the experience of the pandemic could decrease government trust and then this decrease in trust leads to lower support for government surveillance.

$H_5$: Factors that drive concern regarding government tracking should differ from concerns regarding private tracking

Given that previous research has found significant differences in the level of acceptance of tracking between public and private sources in China, and, that trust in government is likely not a factor for accepting private tracking, there should be differences in the factors that predict these two variables.

## Data and summary statistics {#sec-datasummary}

The data for this project were collected via a commercial market research firm in two waves: February 2021 and March 2023. The first survey had an n of 1,500 and the second had an n of 2,000. Questions on the two surveys were identical except for a minor change to a question that referenced a specific date. The timing of the two surveys coincided with two very different points in China's Covid-19 experience. The first survey was conducted approximately seven months after the last round of restrictions had been lifted in the city of Wuhan. At that time, China was essentially closed to foreign travel but otherwise had few day-to-day public health restrictions in place. Nationwide, daily Covid cases hovered around the single digits [@wuhanlo2021]. By March 2023, China found itself at a very different stage. The year 2022 saw the introduction of widespread, intrusive digital monitoring. Many major cities, such as Shanghai, Xi'an, and Shenzhen, underwent prolonged and arduous city-wide lockdowns. At the end of 2022, under the pressure of a spiraling number of cases and widespread protests (known as the White Paper Revolution), China finally abandoned its zero-Covid policy [@mao2022]. March 2023 is far enough removed from the end of the zero-Covid policies for any temporary attitudinal effects of the lockdowns and monitoring to have subsided, yet it is close enough to the end of the policy that differences in attitudes can plausibly be attributed to the Covid-19 experience and not subsequent events. Thus, these two surveys provide excellent data for examining hypotheses 1-6.[^1]

[^1]: All code and data to replicate these results available at the author's GitHub repository.

The demographics of the 2021 and 2023 surveys are presented in @tbl-demographics.

```{r}
#| label: tbl-demographics
#| tbl-cap: Select key demographic variables

demo.qs <- privacy %>% 
  select(`Age` = age,
         `Location` = location,
         `Education` = education,
         `Gender` = sex,
         `Marriage status` = marriage.status,
         `Communist Party member status` = party.member.status,
         `Communist Youth League status` = cyl.status,
         `Income` = income,
         `Year` = year) 

datasummary_balance( ~ 1, data=demo.qs, 
                     output="kableExtra", longtable=TRUE) %>% 
  kable_styling(c("repeat_header"))
```

As is typical with online surveys in China, the sample respondents tend to be younger and more educated. Comparing the two waves, there are some modest demographic differences (notably in education and marital status) between the two samples. As will be shown in Section @sec-analysis, these minor differences do not seem to alter any of the substantive results. Focusing on the 2023 survey, the typical respondent is a male from a small city, married, employed in a white-collar job at a small enterprise, earning approximately 10,000 RMB a month, and holding an urban residence permit (hukou). To simplify the analysis that follows, the variables have been recoded: income is divided into three categories (low, middle, and high) and education into two categories, those with a college education and those without. The regressions in the subsequent sections were tested with alternative specifications of these categorical variables (the code for these regressions is available on the author's website), and the key results remained unchanged.

```{r}
#| label: tbl-respvarindex
#| tbl-cap: "Questions asking about attitudes toward government monitoring"

table.text <- list()

table.text[[1]] <- c("GM1", "There are good reasons for the central government to monitor the activity of users online")
table.text[[2]] <- c("GM2", "There are good reasons for the local government to monitor the activity of users online")
table.text[[3]] <- c("TRACK1", "How comfortable are you with the central government knowing personal details about your activity online?")
table.text[[4]] <- c("TRACK2", "How comfortable are you with the local government knowing personal details about your activity online?")

track.text <- data.frame()

for(line in table.text) {
  track.text <- rbind(track.text, line)
}

kbl(track.text, col.names = NULL, escape=F, align="l") %>% 
  kable_styling(latex_options = c("striped")) %>% 
  column_spec(2, width="5in", bold=FALSE)
```

The key response variable for the following analysis is an index variable created by combining the results of the four questions in @tbl-respvarindex, rescaled to be between zero and one. It is true that previous research has found that Chinese respondents place lower levels of trust in local governments as compared to central governments [@chen2017; @zhong2014], suggesting there may be some differences in attitudes between central and local monitoring. However, the correlation between `GM1` and `GM2` is `r round(cor(as.numeric(privacy$gm1), as.numeric(privacy$gm2)), digits=2)` and the correlation between `TRACK1` and `TRACK2` is `r round(cor(as.numeric(privacy$track4), as.numeric(privacy$track5)), digits=2)`. Additionally, as shown in the online appendices, each of the major regression results in @sec-analysis do not demonstrate major changes if the same variables are regressed on each of the index items individually. Indicating their close relationship, the variables taken together have a Cronbach's $\alpha$ of `r round(ca.tt$alpha, digits=2)`. Intuitively, this high level of relatedness makes sense as while respondents have some background attitudes about the difference between central and local governments, they may not easily be able to identify at which level government tracking occurs.

Finally, there has been some debate regarding the extent of preference falsification of political attitudes in online surveys in China [@carter2024; @jiang2016; @ratigan2020]. If respondents are afraid to reveal their true attitudes toward the government, it could potentially bias the results. To test for preference falsification, the survey instrument also included several list experiment questions, which allowed respondents' attitudes to be inferred indirectly without requiring them to directly state their opinions about the government. List experiments have been utilized in numerous surveys to offer residents a confidential method of expressing their true attitudes on topics such as racial perspectives, experiences of sexual assault, and political views [@redlawsk2010; @moseson2017]. Although @glynn2013 suggests that list experiments should not be viewed as a panacea for the issue of preference falsification, the results of the list experiments (detailed in the online appendices) correspond closely with the answers to the component questions that comprise the response variable index. Additionally, the topic of this survey is less sensitive than other, more directly political research, and should therefore be less likely to provoke significant fear of reprisal among respondents. Overall, the survey data should provide a robust means to differentiate between the hypotheses presented in Section @sec-litreview.

## Analysis {#sec-analysis}

### Predicting citizen attitudes about government monitoring

The first set of models considers the question of which demographic variables predict variation in attitudes toward being tracked by the government. Overall, the central finding is that the demographic variables are relatively weak predictors of acceptance of government monitoring. The key predictor variables included in @tbl-citizenatt are the standard suite of demographic variables, the tech savvy index (`TSI`), and the knowledge index (`KI`). The items used to construct the two indicies variables are listed in @sec-appendix. The Cronbach's $\alpha$ for each of the two variables are `r round(ca.ts$alpha, digits=2)` and `r round(ca.k$alpha, digits=2)` respectively, indicating that the questions are suitable for use in an index. Additionally, this model interacts education and sex with `GPI` - as recent research has suggested that younger generations have different attitudinal patterns than older generations [@harmel2019; @steinhardt2020], and ICT knowledge may also differ significantly by gender. Added to the index variables and the interaction terms are a slate of standard control variables.

```{r}
#| label: tbl-citizenatt
#| tbl-cap: "Demographic predictors of attitude toward government privacy"

citizen.att <- privacy %>% 
  mutate(ts.edu.interact = ts.index * as.numeric(education.binary),
         ts.sex.interact = ts.index * as.numeric(sex),
         track.edu.interact = ts.index * as.numeric(education.binary))

mod1 <- lm(data=citizen.att, total.track.gov.index ~ age + education.binary
           + income.simple + sex + 
           + party.member.status + location)
mod2 <- lm(data=citizen.att, total.track.gov.index ~ age + education.binary 
           + income.simple + sex +  
           + party.member.status + location + year)
mod3 <- lm(data=citizen.att, total.track.gov.index ~ age + education.binary 
           + income.simple + sex +
           + party.member.status + location + year + ts.index)
mod4 <- lm(data=citizen.att, total.track.gov.index ~ age + education.binary 
           + income.simple + sex + 
           + party.member.status + location + year + ts.index + ts.edu.interact)
mod5 <- lm(data=citizen.att, total.track.gov.index ~ age + 
           education.binary + 
           income.simple + sex + 
           party.member.status + location + year + ts.index + ts.sex.interact)
mod6 <- lm(data=citizen.att, total.track.gov.index ~ age + 
           education.binary + 
           income.simple + sex + 
           party.member.status + location + year + k.index)

models <- list(
  "(1)"   = mod1,
  "(2)"   = mod2,
  "(3)"   = mod3,
  "(4)"   = mod4,
  "(5)"   = mod5,
  "(6)"   = mod6
)

sd.text <- paste("Standard deviation of the response variable: ",
                                round(sd(privacy$total.track.gov.index), digits=2))

modelsummary(models,
             gof_omit = 'AIC|BIC|RMSE|Log.Lik.|R2 Adj.',
             stars = TRUE,
             notes = list("Reference values: no college education, low income, female, party member, countryside",
                          sd.text),
             coef_rename = c("age" = "Age",
                             "education.binaryCollege" = "College education",
                             "income.simpleMiddle income" = "Middle income",
                             "income.simpleHigh income" = "High income",
                             "sexMale" = "Male",
                             "party.member.statusNo" = "Not a party member",
                             "locationSmall city" = "Location: small city",
                             "locationMid-sized city" = "Location: mid city",
                             "locationBig city" = "Location: big city",
                             "year2023" = "Year 2023",
                             "ts.index" = "TSI",
                             "ts.edu.interact" = "TSI x education",
                             "ts.sex.interact" = "TSI x sex",
                             "k.index" = "KI"))
```

The coefficients generally indicate effects in the direction expected. Older respondents are more accepting of government tracking, while being male and not being a Communist Party member predict lower acceptance of tracking. Curiously, living in a big city has a positive relationship with tracking acceptance, as does the year 2023. Being tech savvy is positively related to acceptance of tracking, while having knowledge of privacy is negatively associated with the response variable.

However, with respect to the magnitude of the coefficients, the response variable is scaled between zero and one with a standard deviation of `r round(sd(privacy$total.track.gov.index), digits=2)`. Given this scaling, the coefficients of the categorical variables all have rather small effect sizes - being in year 2023 instead of year 2021 produces a shift in the response variable of about a third of a standard deviation. For the other categorical variables, while some reach statistical significance, they have even smaller effect sizes. The tech savvy index has a standard deviation of `r round(sd(privacy$ts.index), digits=2)`. The coefficient of `TSI` indicates the impact of a one unit change in the index (going from its minimum to its maximum) on the response variable. However, since `TSI` is scaled between zero and one, a more typical shift in `TSI` produces an effect only one fifth as large, or about a fifth to a tenth of a standard deviation change in the response variable. Similarly, for `KI`, a typical shift in the predictor variable leads to a nearly negligible change in the response variable.

As can be inferred from the results in this table, the model fit is relatively poor. The poor model fit can also be seen in the very low $R^2$ values and in the extremely poor model residuals (available in the online appendices). Taken together, these results indicate that the available demographic factors do a poor job explaining variation in attitudes towards government tracking, suggesting that the Chinese context may have other factors that are more important and relevant to predicting support for government tracking.

### Does government trust affect attitudes?

Another plausible relationship is that generalized trust in government is a strong predictor of attitudes toward government monitoring. Similar to the key variables in the preceding section, the measure of both local government and central government performance are combined into an index (`GPI`), the definitions of which are also listed in @sec-appendix. As noted in @sec-datasummary, while there has been an observed gap in measurement of local and central government performance in previous literature (and in these surveys), the responses to the two questions are nevertheless highly correlated ($\rho=`r round(cor(as.numeric(privacy$gp1), as.numeric(privacy$gp2)), digits=2)`$). To the extent that they measure disjoint opinions, models `1b` and `1c` take central government performance alone and local government performance alone, as the response variables. As in the previous regression, the usual control variables are included along with an interaction term for education and the main predictor variable.

```{r}
#| label: tbl-governmentatt

gov.att <- privacy %>% 
  mutate(notice.year.interact = track.notice.gov.index * as.numeric(year),
         gp.edu.interact = gp.index * as.numeric(education.binary),
         gp.year.interact = gp.index * as.numeric(year))


mod1 <- lm(data=gov.att, total.track.gov.index ~ age + 
           education.binary +
           income.simple + sex + 
           party.member.status + location + year + gp.index)
mod2 <- lm(data=gov.att, total.track.gov.index ~ age + 
           education.binary +
           income.simple + sex + 
           party.member.status + location + year + gp1.rescale)
mod3 <- lm(data=gov.att, total.track.gov.index ~ age + 
           education.binary +
           income.simple + sex + 
           party.member.status + location + year + gp2.rescale)
mod4 <- lm(data=gov.att, total.track.gov.index ~ age + 
           education.binary +
           income.simple + sex + 
           party.member.status + location + year + gp.index + 
           gp.edu.interact)
mod5 <- lm(data=gov.att, total.track.gov.index ~ age + 
           education.binary +
           income.simple + sex + 
           party.member.status + location + year + gp.index  
           + gp.year.interact)
mod6 <- lm(data=gov.att, total.track.gov.index ~ age + 
           education.binary +
           income.simple + sex + 
           party.member.status + location + year + gp.index + 
           gp.edu.interact + gp.year.interact)

models <- list(
  "(1)"    = mod1,
  "(1a)"   = mod2,
  "(1b)"   = mod3,
  "(2)"    = mod4,
  "(3)"    = mod5,
  "(4)"    = mod6
)

modelsummary(models,
             gof_omit = 'AIC|BIC|RMSE|Log.Lik.|R2 Adj.',
             stars = TRUE,
             notes = list("Reference values: no college education, low income, female, party member, countryside",
                          sd.text),
             coef_rename = c("age" = "Age",
                             "education.binaryCollege" = "College education",
                             "income.simpleMiddle income" = "Middle income",
                             "income.simpleHigh income" = "High income",
                             "sexMale" = "Male",
                             "party.member.statusNo" = "Not a party member",
                             "locationSmall city" = "Location: small city",
                             "locationMid-sized city" = "Location: mid city",
                             "locationBig city" = "Location: big city",
                             "year2023" = "Year 2023",
                             "gp.index" = "GPI",
                             "gp.edu.interact" = "GPI x education",
                             "gp.year.interact" = "GPI x year",
                             "gp1.rescale" = "CG performance",
                             "gp2.rescale" = "LG performance"))
```

The coefficients on in @tbl-governmentatt indicate that government performance is a much stronger and positive predictor of attitudes towards government tracking than the index demographic variables. In model `1`, a one standard deviation increase in the government performance index (`r round(sd(privacy$gp.index), digits=2)`) predicts about a one third of a standard deviation change in attitudes towards government tracking, a relatively significant effect for an attitudinal survey. Local government trust is a little weaker of a predictor variable than central government trust but the two coefficients are fairly similar, indicating their suitability for use in an index. Additionally, the two interaction terms are also both significant, though education only marginally so. The effect of these interaction terms can be viewed in @fig-marginplotperform. Education increases support for government tracking while year 2023 increases the impact. Finally, the model fit diagnostics have improved, indicating a better model fit.

**Figure 1 about here**

As expected, government performance, when controlling for demographic factors, is a relatively strong predictor of the acceptance of government surveillance. The model suggests that a positive view of government performance is associated with an increased acceptance of government monitoring. However, this relationship could be more complex than a simple multiple variable regression specification. To further examine how these factors influence one another, the next section introduces a mediation model aimed at understanding how the relationship may have evolved owing to the events of 2022.

### Changing attitudes since the pandemic

The following directed acyclic graph (DAG) indicates the hypothesized causal process that generates the observed outcome variable, tracking acceptance. In @fig-dag, `TA` represents tracking acceptance, `GP` represents government performance approval, `DEMO` represents demographic characteristics, and `COVID` represents respondents' Covid-19 experience.

To operationalize this model, the first step is to create a latent demographics construct with the demographic variables previously used in regressions in the earlier sections loading onto this construct. `COVID` is operationalized by the `year` variable. Admittedly, this is not a precise operationalization of the Covid experience - the `year` variable actually measures all changes between survey waves not accounted for by other variables. With respect to government tracking acceptance attitudes, however, this assumption can be justified by the fact that the Covid-19 experience was both a daily and often traumatic one for the Chinese public; it was a time period that involved constant and invasive technological monitoring. If the model does indicate that the `year` variable predicts significant change in the response variable over the two year difference between survey waves, it would be hard to imagine any other plausible cause as no other large shifts in technological control existed in the roughly two years between survey waves. Nevertheless, it is important to keep in mind that it is only a proxy measurement. These variables (`year` for `COVID`, `GP`, `TA`, and `DEMO`) are entered into a structural equation model with paths constrained to that described by the DAG in @fig-dag and then the parameters are estimated using the `lavaan` library in `R`.

**Figure 2 about here**

```{r}
#| label: tbl-mediationmodel
#| tbl-cap: "Mediation model results"

sem.data <- privacy %>% 
  mutate(education.binary = as.numeric(education.binary),
         income.simple = as.numeric(income.simple),
         sex = as.numeric(sex),
         party.member.status = as.numeric(party.member.status),
         location = as.numeric(location))

specmod <- "
### Specify directional paths/relations
# Demographic features
demo =~ s*age + t*education.binary + u*income.simple + v*sex + w*party.member.status + x*location
# Path a
gp.index ~ a*demo
# Path b
total.track.gov.index ~ b*gp.index 
# Path c 
total.track.gov.index ~ c*demo
# Path d
total.track.gov.index ~ d*year
# Path e
gp.index ~ e*year

### Specify indirect effect (a*b)
ab := a*b
de := d*e
"

# Estimate mediation analysis model & assign to fitted model object
fitmod <- sem(specmod,  # name of specified model object 
              data=sem.data)  # name of data frame object

# Print summary of model results
modelsummary(fitmod,
             stars = TRUE,
             coef_omit = "demo =~*",
             coef_rename = c("gp.index ~ demo" = "DEMO to GP",
                             "total.track.gov.index ~ gp.index" = "GP to TA",
                             "total.track.gov.index ~ demo" = "DEMO to TA",
                             "total.track.gov.index ~ year" = "COVID to TA",
                             "gp.index ~ year" = "COVID to GP",
                             "ab := a*b" = "DEMO to GP to TA",
                             "de := d*e" = "COVID to GP to TA"),
              notes = list("Demographic factor variable loadings omitted"))
```

The results from the analysis in @tbl-mediationmodel confirm some previous findings and also reveal some interesting new features of the data. As before, government performance plays a crucial role in determining tracking acceptance. Similarly, demographic factors do help predict tracking acceptance, but only slightly. Demographics do not aid in predicting views on government performance, so it is unsurprising that demographics do not have an indirect effect on tracking acceptance through government performance either. However, the Covid-19 experience, as operationalized by the year variable, 1) positively increases tracking acceptance (direct path), 2) negatively reduces government performance evaluations (direct path), and 3) negatively decreases tracking acceptance through government performance evaluations (indirect path). The size of the coefficients indicates that the sum of the effects is still positive on tracking acceptance. These results suggest that the Covid-19 experience in China did have the effect identified by @you2024, which resulted in the hypothesized decrease in acceptance of government tracking. However, this decrease in support was offset by the direct effect of Covid-19 on the acceptance of tracking. A plausible interpretation of this is that respondents agree with @kostka2024's finding: the tracking during Covid-19 lockdowns was deemed necessary, but due to the government's incompetence in responding to the spread of the virus, they were less likely to positively agree than they might otherwise have been.

### Comparing attitudes to private monitoring

Finally, it is interesting to compare the determinants of government tracking attitudes with those that determine attitudes toward private tracking of personal information. To compare these two sets of attitudes, @tbl-privatepublic includes models that use the previous acceptance of government tracking index (`Public TA`) as the variable alongside a similarly constructed index variable that measures acceptance of private monitoring (`Private TA`).

```{r}
#| label: tbl-privatepublic
#| tbl-cap: "Comparison of public vs. private tracking acceptance"
#| tbl-pos: "H"

comp.att <- privacy 

sd.text1 <- paste("Standard deviation of Public TA is: ",
                                round(sd(privacy$total.track.gov.index), digits=2))
sd.text2 <- paste("Standard deviation of Private TA is: ",
                                round(sd(privacy$pm.index), digits=2))

mod1 <- lm(data=comp.att, total.track.gov.index ~ age + 
           education.binary +
           income.simple + sex + 
           party.member.status + location + year + ts.index)
mod2 <- lm(data=comp.att, total.track.gov.index ~ age + 
           education.binary +
           income.simple + sex + 
           party.member.status + location + year + k.index)
mod3 <- lm(data=comp.att, total.track.gov.index ~ age + 
           education.binary +
           income.simple + sex + 
           party.member.status + location + year + gp.index)
mod4 <- lm(data=comp.att, pm.index ~ age + 
           education.binary +
           income.simple + sex + 
           party.member.status + location + year + ts.index)
mod5 <- lm(data=comp.att, pm.index ~ age + 
           education.binary +
           income.simple + sex + 
           party.member.status + location + year + k.index)
mod6 <- lm(data=comp.att, pm.index ~ age + 
           education.binary +
           income.simple + sex + 
           party.member.status + location + year + gp.index)

models <- list(
  "(1a)"    = mod1,
  "(1b)"   = mod2,
  "(1c)"   = mod3,
  "(2a)"    = mod4,
  "(2b)"    = mod5,
  "(2c)"    = mod6
)

tab <- modelsummary(models,
             gof_omit = 'AIC|BIC|RMSE|Log.Lik.|R2 Adj.',
             stars = TRUE,
             notes = list("Reference values: no college education, low income, female, party member, countryside",
                          sd.text1,
                          sd.text2),
             coef_rename = c("age" = "Age",
                             "education.binaryCollege" = "College education",
                             "income.simpleMiddle income" = "Middle income",
                             "income.simpleHigh income" = "High income",
                             "sexMale" = "Male",
                             "party.member.statusNo" = "Not a party member",
                             "locationSmall city" = "Location: small city",
                             "locationMid-sized city" = "Location: mid city",
                             "locationBig city" = "Location: big city",
                             "year2023" = "Year 2023",
                             "ts.index" = "TSI",
                             "k.index" = "KI",
                             "gp.index" = "GPI"))

tab %>% 
  add_header_above(c(" " = 1, "Public TA" = 3, "Private TA" = 3))
```

The results here suggest that the determinants of attitudes towards private company tracking are somewhat different than those that determine attitudes towards public tracking. The `year` variable is not significant for the private tracking models, while the tech savvy coefficient has roughly doubled. Unsurprisingly, government performance is also not related to private tracking acceptance. Finally, the intercept is generally lower for private tracking acceptance, indicating that respondents are less willing to accept private tracking, all things being equal.

These results lend support to the hypothesis that acceptance of public tracking has different determinants than those for private tracking and also supports previous research that finds a significant difference between acceptance of these two types of monitoring. The `year` variable being insignificant for the private tracking indicates that the pandemic-era tracking was not perceived as being fundamentally related to commercial monitoring.

## Conclusion {#sec-conclusion}

China's experience with Covid-19 has significantly altered attitudes towards government tracking—despite a decrease in trust in the state, overall support for tracking increased. Demographic and informational variables do not provide strong predictive power for attitudes towards government tracking. Additionally, the factors that predict acceptance of government tracking do not show a meaningful correlation with acceptance of private tracking.

These results carry significant implications for the current body of literature. Contrary to the literature on demographic characteristics and privacy, this study found that demographic variables have very little predictive power, whether they are personal variables or measures of technological knowledge. This indicates that generalized privacy attitudes may have determinants that differ from those influencing attitudes toward government monitoring in China. Such a conclusion aligns with research by Nam and Steinfeld on American attitudes towards privacy \[\@nam2019; \@steinfeld2017\]. Furthermore, while the finding that government trust is a strong predictor of attitudes is consistent with much of the existing literature, the idea that public events can significantly shift attitudes is a novel contribution. Davis (2004) suggested that 9/11 may have established a critical context that influenced whether respondents deemed surveillance necessary and acceptable, which is compatible with the findings of this study. Lastly, while the determinants of acceptance for private tracking in China require more investigation than what is presented here, they appear to differ considerably from those of government tracking, suggesting distinct underlying mechanisms at play.

One limitation of this research is that it inquires solely about generalized acceptance of tracking. Kostka (2021) is among the few studies to concentrate on specific technological applications, such as facial recognition technology. Further research into the specific technological methods and aspects of privacy that generate variations in acceptance would be beneficial. Moreover, this study exclusively addressed a crisis context where trust in government declined but the public nonetheless acknowledged the general societal necessity for the technology. Analyses of other scenarios, involving changes in government trust levels paired with variations in public acceptance of technological monitoring, could reinforce the conclusions of this work.

The study suggests that context and the independent acceptance of the rationale for tracking both significantly impact attitudes towards online privacy. This is a crucial insight for governments to consider, as AI and big data continue to expand the interactions between citizens and state authorities.

{{< pagebreak >}}

## Biography

Andrew W. MacDonald is assistant professor in the Division of Social Sciences at Duke Kunshan University (China).His research interests lie primarily in Chinese public opinion and their behavior online. He would like to thank Yuchen (Nathan) Cao for his invaluable assistance in organizing the surveys and the Duke Kunshan Petal Lab for helping to test the survey instrument.

{{< pagebreak >}}

## References

::: {#refs}
:::

{{< pagebreak >}}

## Appendix {#sec-appendix}

### Index variable definitions

```{r}
#| label: tbl-tsindexvars
#| tbl-cap: Tech savvy index variable construction
#| tbl-pos: "H"

table.text <- list()

table.text[[1]] <- c("Q1", "How would you rate your general ability to use a computer?")
table.text[[2]] <- c("Q2", "How would you rate your skill at fixing a computer? ")
table.text[[3]] <- c("Q3", "How would you rate your ability to program a computer? ")

ts.text <- data.frame()

for(line in table.text) {
  ts.text <- rbind(ts.text, line)
}

kbl(ts.text, col.names = NULL) %>% 
  kable_styling(latex_options = c("striped"))  
```

```{r}
#| label: tbl-pkindexvars
#| tbl-cap: Privacy knowledge index variable construction
#| tbl-pos: "H"

table.text <- list()

table.text[[1]] <- c("Q1", "I am very concerned about my privacy online")
table.text[[2]] <- c("Q2", "I spend a lot of time reading about technology related privacy issues")
table.text[[3]] <- c("Q3", "In the last year, I have had discussions with my friends about online privacy issues")
table.text[[4]] <- c("Q4", "I feel like I know exactly how much privacy I have online")
table.text[[5]] <- c("Q5", "Have you heard of the social credit system (official terminology)?")

kw.text <- data.frame()

for(line in table.text) {
  kw.text <- rbind(kw.text, line)
}

kbl(kw.text, col.names = NULL) %>% 
  kable_styling(latex_options = c("striped")) 
```

```{r}
#| label: tbl-gpindexvars
#| tbl-cap: Government performance index variable construction
#| tbl-pos: "H"


table.text <- list()

table.text[[1]] <- c("Q1", "Overall, I’m happy with the performance of the central government")
table.text[[2]] <- c("Q2", "Overall, I’m happy with the performance of my local government")

gp.text <- data.frame()

for(line in table.text) {
  gp.text <- rbind(gp.text, line)
}

kbl(gp.text, col.names = NULL) %>% 
  kable_styling(latex_options = c("striped")) %>% 
  column_spec(2, width="5in", bold=FALSE)
```

### Figures

```{r}
#| label: fig-marginplotperform
#| fig-cap: "Marginal effect plots of interaction terms"
#| fig-subcap: 
#|    - "GPI x education"
#|    - "GPI x year"

plot_model(mod6, type = "pred", 
           terms = c("gp.index", "education.binary"),
           ci.lvl = NA)
plot_model(mod6, type = "pred", 
           terms = c("gp.index", "year"),
           ci.lvl = NA)
```

```{r}
#| label: fig-dag
#| fig-cap: "Causal process"

dag <- dagitty("dag {
COVID [pos=\"-0.212,-1.176\"]
DEMO [exposure,pos=\"-1.699,-0.231\"]
GP [pos=\"-0.964,-0.841\"]
TA [outcome,pos=\"-0.188,-0.236\"]
COVID -> GP
COVID -> TA
DEMO -> GP
DEMO -> TA
GP -> TA
}")

ggdag(dag, layout="circle") +
  theme_dag()
```